{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification of Rock Paper Scissors by knightbearr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUVp26gnC-Yp"
      },
      "source": [
        "# **Image Classification of Rock-Paper-Scissors Pictures using Convolutional Neural Network (CNN)**\n",
        "\n",
        "`@knightbearr`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG-S8pSIDr1R"
      },
      "source": [
        "## **Import Module 1**\n",
        "\n",
        "import module yang diperlukan untuk penelitian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9vytWU0C8a-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35ORXzDADyyh"
      },
      "source": [
        "## **Upload Data**\n",
        "\n",
        "upload data yang ingin diteliti."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Ql3kl9EGNR"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYVRg2EXEIv4"
      },
      "source": [
        "## **Since we want to use the Dataset, we must extract them first using *zipfile* library yang sudah di siapkan di bagian Import Modul, dan pastikan kita sudah meng-importnya.** \n",
        "\n",
        "Algoritmanya sebagai berikut :\n",
        "\n",
        "1. tampung tmp/file sementara dataset tersebut kedalam variable (***local_zip***)\n",
        "2. tampung file/sementara dataset/rps-cv-images kedalam variable (***base_dir***)\n",
        "3. extract zipfile menggunakan funsgi *ZipFile* yang tersedia pada modul zipfile yang sudah kita import, lalu masukan dua argument, yang pertama file sementara yang sudah kita tampung pada variable **local_zip** dan yang kedua itu 'r' untuk membaca file tersebut\n",
        "4. gunakan fungsi ***extractall()*** untuk mengekstrak semua file di dalam file \n",
        "5. dan menutup file dengan memanggil fungsi ***close()***, karena jika tidak memanggil fungsi close, catatan penting tidak akan ditulis, info lebih lanjutnya tentang module zipfile bisa dilihat disini https://docs.python.org/3/library/zipfile.html\n",
        "6. buat variable base_dir untuk menampung tmp image/ data sementara image\n",
        "7. buat variable train_dir dan menggunakan module os.path.join() dan beri 2 argumen, argumen pertama itu base_dir, dan kedua 'train' dan untuk yang validation itu sama, tetapi argumen terakhir menggunakan 'val'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFX1ADsSEK_g"
      },
      "source": [
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_extract = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_extract.extractall('/tmp')\n",
        "zip_extract.close()\n",
        "\n",
        "base_dir = '/tmp/rockpaperscissors/rps-cv-images'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-asVihqCESVA"
      },
      "source": [
        "## **Check Direktori**\n",
        "\n",
        "chech direktori menggunakan fungsi ***listdir()*** yang berada pada library ***os*** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEo6VT5mEUnZ"
      },
      "source": [
        "os.listdir('/tmp/rockpaperscissors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAFmO7ZiEXiS"
      },
      "source": [
        "os.listdir('/tmp/rockpaperscissors/rps-cv-images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9jJbH6UEY4P"
      },
      "source": [
        "## **Data Processing dengan Image Augmentation yang menjadi kriteria submission**\n",
        "\n",
        "Algoritmanya sebagai berikut\n",
        "\n",
        "1. buat variable ***train_datagen***, dan gunakan fungsi ***ImageDataGenerator***.\n",
        "2. masukan ***rescale*** untuk men scale data.\n",
        "3. masukan ***zoom_range*** untuk men zoom data.\n",
        "4. masukan ***rotation_range*** untuk mengatur rotasi.\n",
        "5. masukan ***horizontal_flip*** untuk membalikkan gambar/foto.\n",
        "6. masukan ***fill_mode*** untuk memasukan mode yang kita inginkan, disini saya menggunakan mode ***wrap/membungkus***.\n",
        "7. masukan ***validation_split*** untuk mensplit dataset sebesar 40%.\n",
        "8. masukan ***height_shift_range*** untuk mengatur rentang pergeseran ketinggian.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYo30bntEapQ"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=(1./225),\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=25,\n",
        "    horizontal_flip=True,\n",
        "    shear_range=0.2,\n",
        "    fill_mode='wrap',\n",
        "    validation_split=0.4,\n",
        "    height_shift_range=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKfW9xOaE9SZ"
      },
      "source": [
        "## **Menyiapkan Data Untuk Model**\n",
        "\n",
        "Sebelum pindah ke pemodelan data, kita harus mengambil jalur ke direktori target dan menghasilkan kumpulan data tambahan.\n",
        "\n",
        "Algoritma nya sebagai berikut :\n",
        "\n",
        "1. Buat variable ***train_generator*** dan ***validation_generator*** yang menampung variable ***train_datagen*** dan ***validation_generator***  yang telah kita buat sebelumnya, lalu gunakan fungsi ***flow_flow_directory***.\n",
        "2. Masukan file ***base_dir*** untuk jalur ke direktori target.\n",
        "3. Masukan ***target_size*** untuk merubah semua resolusi gambar.\n",
        "4. Masukan ***shuffle*** untuk mengatur acak data.\n",
        "5. Masukan ***color_mode*** untuk mengatur warna data.\n",
        "6. Masukan ***class_mode*** categorical untuk menentukan jenis label array, kita menggunakan categorical karena kita mempunyai 3 kelas gambar.\n",
        "7. Masukan ***interpolation*** untuk meresampling citra gambar jika ukuran target berbeda dari gambar yang dimuat.\n",
        "8. Masukan ***batch_size_data*** untuk ukuran kumpulan data.\n",
        "9. Masukan ***subset*** training karena variable ini ingin supaya kita menampung data pelatihan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyqAp-q4FBYy"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(100, 150),\n",
        "    shuffle=True,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    interpolation='nearest',\n",
        "    batch_size=32,\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(100, 150),\n",
        "    shuffle=True,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    interpolation='nearest',\n",
        "    batch_size=32,\n",
        "    subset='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYHGjNdyFFjX"
      },
      "source": [
        "## **Buat CNN Arsitektur**\n",
        "\n",
        "karena kita ingin membuat model untuk mengklasifikasikan gambar maka kita akan membuat CNN dua dimensi (2D).\n",
        "\n",
        "kita menggunakan ***tf.keras.models.Sequantial()***, karena ini merupakan kriteia submission yang telah diberikan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti9U4cYWFVsT"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 150, 3)),\n",
        "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                                    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                                    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                                    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(3, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmUtRpZLFYFB"
      },
      "source": [
        "## **Compile Model**\n",
        "\n",
        "Karena model yang kita compile masuk kedalam klasifikasi multi-kelas, jadi kita harus menggunakan binary ***categorical_cossentrpy***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5SNg2-tFZ_R"
      },
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TA3AFZRFcDp"
      },
      "source": [
        "## **Dan Latih Model Kita**\n",
        "\n",
        "gunakan fungsi fit untuk melatih model kita"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGy9EBDcFeFx"
      },
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=25,\n",
        "    epochs=25, # Atur Epoch sesuai keinginan anda\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=5,\n",
        "    verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQgEpmRuFt4Z"
      },
      "source": [
        "## **Final**\n",
        "\n",
        "upload gambar menggunakan code seperti berikut.\n",
        "\n",
        "Algoritmanya sebagai berikut :\n",
        "\n",
        "1. Saya membuat variable uploaded untuk mengambil data/file, dan gunakan fungsi ***upload()*** untuk mengupload gambar yang ingin kita prediksi.\n",
        "2. Saya membuat perulangan dengan iterasi fn di variables uploaded yang saya buat sebelumnya, dan hanya mengambil Keys nya saja.\n",
        "3. Saya membuat variable img_src untuk menampung data image, dan saya menggunakan target_size yang sama dengan data train_generator sebelumnya.\n",
        "4. Saya membuat variable imgplot untuk menunjukan gambar/foto.\n",
        "5. Saya membuat variable x untuk memasukan gambar kedalam array.\n",
        "6. Saya juga membuat variable yang sama dengan sebelumnya untuk menambah dimensi menggunakan library numpy.\n",
        "7. Saya juga membuat variable images untuk me vstack atau untuk dapat menerima lebih dari 2 array dalam argumen urutan.\n",
        "8. Saya juga membuat variable classes untuk menampung model predict, dan memasukan argumen variable images, dan juga batch_size sebesar 15.\n",
        "9. Saya juga memasukan fungsi ***print()*** untuk memanggil fn\n",
        "10. saya membuat conditional if, elif statment untuk memprediksi gambar yang ditunjukkan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZK34Xr4F6RD"
      },
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    path = fn\n",
        "    img_src = image.load_img(path, target_size=(100, 150))\n",
        "    imgplot = plt.imshow(img_src)\n",
        "    x = image.img_to_array(img_src)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images, batch_size=15)\n",
        "\n",
        "    print(fn)\n",
        "    if classes[0, 0] == 1:\n",
        "        print('rock')\n",
        "    elif classes[0, 1] == 1:\n",
        "        print('paper')\n",
        "    elif classes[0, 2] == 1:\n",
        "        print('scissors')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}